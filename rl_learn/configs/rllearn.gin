import dl.util.gin_torch_externals
import dl.trainer
import dl.util
import rl_learn.util

optim.Adam.lr = 0.0007
optim.Adam.betas = (0.9, 0.999)
optim.Adam.eps = 0.00001

RunRLLEARN.use_gae = False

PPO.env_fn = @make_env_
PPO.nenv = 1
PPO.optimizer = @optim.Adam
PPO.gamma = 0.99
PPO.lambda_ = 0.95
PPO.clip_param = 0.2
PPO.steps_per_iter = 64
PPO.batch_size = 8
PPO.epochs_per_iter = 4
PPO.max_grad_norm = 0.5
PPO.ent_coef = 0.01
PPO.vf_coef = 0.5
PPO.norm_advantages = False
PPO.norm_observations = False

Trainer.maxt = 500000
Trainer.seed = 0
Trainer.eval = False
Trainer.save_period = 10000

Checkpointer.min_ckpt_period = 10000
Checkpointer.max_ckpts_to_keep = 1


make_env_.gamma = 0.99
make_env_.noise = 0.

make_env_.expt_id = 6
make_env_.descr_id = 9
make_env_.lang_enc = "onehot"
make_env_.mode = "paper"
make_env_.lang_coeff = 0.
